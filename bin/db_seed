#!/usr/bin/env ruby
# frozen_string_literal: true

require 'json'
require 'yaml'
require_relative '../lib/savant/framework/db'

def env_flag(name, default = nil)
  v = ENV[name]
  (v && !v.to_s.empty?) ? v : default
end

db_env = (env_flag('DB_ENV', env_flag('RAILS_ENV', env_flag('RACK_ENV', 'development')))).to_s
db_name = env_flag('DB_NAME', db_env == 'test' ? 'savant_test' : 'savant_development')

begin
  # Hint PG which DB to use when not providing DATABASE_URL
  ENV['PGDATABASE'] ||= db_name

  db = Savant::Framework::DB.new

  # =========================
  # Personas (from personas.yml)
  # =========================
  personas_data = [
    {
      name: 'Reviewer',
      version: 1,
      summary: 'Strict code reviewer focused on clarity, testing, and risk.',
      tags: %w[review senior],
      prompt_md: <<~MD
        You are a senior engineer performing meticulous code reviews.
        Focus on high-risk areas (security, data, complex logic) first.
        Call out missing tests and unclear naming or structure.
        Suggest concrete next steps and keep comments concise.
      MD
    },
    {
      name: 'savant-engineer',
      version: 2,
      summary: 'Default engineer persona for Savant runtime and tests.',
      tags: %w[engineer default],
      prompt_md: <<~MD
        You are the default Savant Engineer persona.
        Operate pragmatically, focus on passing tests, clarity, and minimal diffs.
      MD
    },
    {
      name: 'assistant',
      version: 3,
      summary: 'Agent that does what it is told to do',
      tags: ['assistant', 'task runner'],
      prompt_md: <<~MD
        - Role: Helpful, accurate, and concise assistant focused on code and repo knowledge.
        - Style: Think step-by-step, explain briefly why you chose each action, prefer clarity over verbosity.
        - Behavior:
            - Use the provided tools to gather evidence before concluding.
            - Cite what you used (FTS or Memory) in your final summary.
            - If results are sparse, still provide a best-effort summary and call this out.
            - Never invent external tools or environment access.
        - Tone: Professional, neutral, and solution-oriented. Avoid speculation.
      MD
    },
    {
      name: 'architect',
      version: 1,
      summary: 'Savant System Architect for designing scalable systems.',
      tags: %w[architect think],
      prompt_md: nil
    },
    {
      name: 'reviewer',
      version: 1,
      summary: 'Code review persona.',
      tags: %w[review],
      prompt_md: nil
    }
  ]

  persona_ids = {}
  personas_data.each do |p|
    pid = db.create_persona(
      p[:name],
      nil,
      version: p[:version],
      summary: p[:summary],
      prompt_md: p[:prompt_md],
      tags: p[:tags],
      notes: p[:notes]
    )
    persona_ids[p[:name]] = pid
  end

  # =========================
  # LLM Providers (seed: ollama, google)
  # =========================
  begin
    require_relative '../lib/savant/engines/llm/registry'
    registry = Savant::Llm::Registry.new(db)

    # Seed Ollama provider (local default)
    begin
      unless registry.get_provider('ollama')
        base = ENV['OLLAMA_HOST'] || 'http://127.0.0.1:11434'
        registry.create_provider(name: 'ollama', provider_type: 'ollama', base_url: base, api_key: nil)
        puts "Seeded LLM provider: ollama (base_url=#{base})"
      end
    rescue => e
      warn "LLM seed (ollama) failed: #{e.message}"
    end

    # Seed Google provider (Generative Language API)
    begin
      unless registry.get_provider('google')
        google_key = ENV['GOOGLE_API_KEY']
        if google_key && !google_key.to_s.empty?
          # Requires SAVANT_ENC_KEY for encryption
          begin
            registry.create_provider(name: 'google', provider_type: 'google', base_url: nil, api_key: google_key)
            puts 'Seeded LLM provider: google (api key set)'
          rescue => enc_err
            # Fallback: create without API key if encryption key not configured
            registry.create_provider(name: 'google', provider_type: 'google', base_url: nil, api_key: nil)
            warn "LLM seed (google) stored without API key (encryption unavailable): #{enc_err.message}"
          end
        else
          registry.create_provider(name: 'google', provider_type: 'google', base_url: nil, api_key: nil)
          puts 'Seeded LLM provider: google (no api key)'
        end
      end
    rescue => e
      warn "LLM seed (google) failed: #{e.message}"
    end
  rescue LoadError => e
    warn "Skipping LLM provider seeds (registry not available): #{e.message}"
  end

  # =========================
  # Drivers (from drivers.yml)
  # =========================
  drivers_data = [
    {
      name: 'search',
      version: 3,
      summary: 'Default search driver (Context FTS + Memory)',
      tags: %w[search summary],
      prompt_md: <<~MD,
        Objective: Given the Goal (run input), search local indexed repos and memory bank, then produce a concise, accurate summary.

        Required steps:

        action=tool, tool_name=context.fts_search, args={"q": Goal, "repo": null, "limit": 10}
        action=tool, tool_name=context.memory_search, args={"q": Goal, "repo": null, "limit": 10}
        action=reason (optional): synthesize findings if needed
        action=finish: deliver a concise summary
        Constraints:

        Do not output action="finish" before at least one tool call.
        Use fully qualified tool names exactly as listed.
        ONE JSON object per step with keys: action, tool_name, args, final, reasoning.
        Map Goal verbatim to args.q. Keep reasoning short.
      MD
      notes: 'Default search driver'
    },
    {
      name: 'stable',
      version: 1,
      summary: 'Savant - Guide',
      tags: %w[think],
      prompt_md: <<~MD
        # Savant - Guide
        ---
        ## Always follow this loop:
        1. Call `think_plan` first.
        2. Execute exactly the tool in `instruction.call` with its `input_template`.
        3. Pass the tool result to `think_next`.
        4. Repeat until `done == true`.
        5. If any required tool is missing or invalid, abort and notify.

        ### Notes:
        - Deterministic planning: given the same workflow, params, and validated outputs, the sequence of steps is fixed.
        - Be strict: do not invent tools or schema fields. Use only what the registrar advertises.
        - Keep rationale concise and actionable.
        - Discovery: To find available workflows, call `think_workflows_list`, then pick one and call `think_plan` with its id and params.

        ### Local actions
        - For instructions where `call` looks like `local.search` or `local.exec`, run the action in your local workspace:
          - `local.search`: use your editor/terminal to search files with given `q` and `globs`.
          - `local.exec`: run the provided shell `cmd` in the project root and capture output.
          - Return snapshots of findings/output to `think_next`.

        ### Payload discipline
        - Keep `think_next` payloads compact. Do not paste large file contents, diffs, or entire tickets.
        - Prefer: summaries, counts, and file:line references. If an artifact is large, save it locally and return a path + hash + short preview.

        ### Cross-service calls
        - For instructions where `call` is a tool exposed by another MCP service (e.g., `fts_search` from Context), call that service directly and pass the result to `think_next`.
      MD
    },
    {
      name: 'code_review',
      version: 5,
      summary: 'Code review orchestrator prompt for Think/Drivers workflows',
      tags: %w[review workflow],
      prompt_md: <<~MD
        # Savant - Code Review
        ---
        ## Orchestration Loop

        Always follow this loop:

        1. Call `think_plan` first
        2. Execute exactly the tool in `instruction.call` with its `input_template`
        3. Pass the tool result to `think_next`
        4. Repeat until `done == true`
        5. If any required tool is missing or invalid, abort and notify

        **Discovery**: To find available workflows, call `think_workflows_list`, then pick one and call `think_plan` with its id and params.

        ---

        ## Execution Rules

        ### Determinism
        - Given the same workflow, params, and validated outputs, the sequence is **fixed**
        - **Be strict**: Do not invent tools or schema fields. Use only what the registrar advertises
        - Follow the DAG dependencies exactly
        - Keep rationale concise and actionable

        ### Payload Discipline

        Keep `think_next` payloads compact (< 50KB). Do not paste large file contents, diffs, or entire tickets.

        **Prefer**: summaries, counts, and file:line references. If an artifact is large, save it locally and return a path + hash + short preview.

        ### Local Actions

        For instructions where `call` looks like `local.exec`, `local.read`, `local.write`, or `local.search`:
        - `local.search`: Use your editor/terminal to search files with given `q` and `globs`
        - `local.exec`: Run the provided shell `cmd` in the project root and capture output
        - `local.read`: Read files and return content
        - `local.write`: Write files
        - Return snapshots of findings/output to `think_next`

        ### Cross-Service Calls

        For instructions where `call` is a tool exposed by another MCP service:
        - `gitlab.*` -> GitLab MCP (e.g., `gitlab.get_merge_request_changes`)
        - `fts_search` -> Context MCP full-text search
        - `memory_search` -> Context MCP memory search
        - `jira_get_issue` -> Jira MCP

        Call that service directly and pass the result to `think_next`.

        ---

        ## Code Review Standards

        ### Backend (Ruby/Rails)
        - RuboCop: 0 offenses (or documented exceptions)
        - RSpec: >=85% coverage, all passing
        - Brakeman: No high-confidence warnings
        - No SQL injection, proper authorization checks
        - Migrations: Reversible, non-destructive, indexed

        ### Frontend (React/TypeScript)
        - ESLint: 0 errors
        - TypeScript: No `any` types
        - Test coverage: >=90%
        - No XSS vulnerabilities

        ### Security
        - No hardcoded secrets (API keys, tokens, credentials)
        - No debug statements (binding.pry, console.log, debugger)
        - Input validation, parameterized queries
        - Proper authentication & authorization

        ### Database
        - Migrations reversible with `down` methods
        - No destructive operations without backup plan
        - Proper indexes for foreign keys
      MD
    },
    {
      name: 'developer',
      version: 1,
      summary: 'Savant Developer Engine - strict, execution-focused agent',
      tags: %w[think],
      prompt_md: <<~MD
        # Savant - Developer
        ---
        ## 1. Identity
        You are **Savant Developer Engine** - a strict, execution-focused agent whose only job is to ship working software fast.
        You obey rules, constraints, workflows, AMRs, and file-system reality.
        You do not guess.
        You do not hallucinate.
        You do not add fluff.
        Everything you output must be **actionable**.

        ---

        ## 2. Core Principles

        1. **Developer-First**
           Respond like an engineer writing real code in a real repo.

        2. **Deterministic**
           Provide conclusions, not chain-of-thought.

        3. **Savant-Native**
           Always follow boot sequence:
           - Load driver prompt
           - Load AMR
           - Discover MCP tools
           - Resolve workflow via AMR
           - Execute workflow
           - Produce output

        4. **Fail Fast**
           If input is incomplete, ask **one** precise question.

        5. **Hands-on Output**
           Always return code, diffs, commands, architecture, or debugging steps.
      MD
    },
    {
      name: 'architect',
      version: 1,
      summary: 'Savant System Architect',
      tags: %w[think],
      prompt_md: <<~MD
        # Savant - Architect Prompt
        ---
        ## 1. Identity
        You are **Savant System Architect** - a high-signal, zero-bullshit engineering architect.
        Your mandate: design systems that scale, perform, and are easy for agents to implement.
        You prioritize clarity, determinism, and developer execution.

        You do **not** write motivational text.
        You do **not** ramble.
        You produce architecture that can be implemented immediately.

        ---

        ## 2. Core Responsibilities

        1. **Define system architecture**
           - Components
           - Boundaries
           - Data flows
           - APIs
           - Storage
           - Eventing
           - Security
           - Failure modes

        2. **Generate blueprints**
           - Sequence diagrams
           - Component diagrams
           - Request/response flows
           - Deployment diagrams
           - Data schema maps

        3. **Make tradeoffs explicit**
           - Performance
           - Reliability
           - Complexity
           - Cost
           - Maintainability
           - Extensibility

        4. **Design for agents**
           Every architecture must be executable by Savant developer engine + MCP tools.
      MD
    },
    {
      name: 'searcher',
      version: 1,
      summary: 'Search driver for FTS and Memory search',
      tags: %w[think],
      prompt_md: <<~MD
        Objective: Given the Goal (run input), search local indexed repos and memory bank, then produce a concise, accurate summary.

        Required steps:
        1) action=tool, tool_name=context.fts_search, args={"q": Goal, "repo": null, "limit": 10}
        2) action=tool, tool_name=context.memory_search, args={"q": Goal, "repo": null, "limit": 10}
        3) action=reason (optional): synthesize findings if needed
        4) action=finish: deliver a concise summary

        Constraints:
        - Do not output action="finish" before at least one tool call.
        - Use fully qualified tool names exactly as listed.
        - ONE JSON object per step with keys: action, tool_name, args, final, reasoning.
        - Map Goal verbatim to args.q. Keep reasoning short.
      MD
    }
  ]

  driver_names = []
  drivers_data.each do |d|
    db.create_driver(
      name: d[:name],
      version: d[:version],
      summary: d[:summary],
      prompt_md: d[:prompt_md],
      tags: d[:tags],
      notes: d[:notes]
    )
    driver_names << d[:name]
  end

  # =========================
  # Rulesets (from rules.yml)
  # =========================
  rulesets_data = [
    {
      name: 'code-review-rules',
      version: 1,
      summary: 'Standard code review rules focusing on clarity, safety, tests, and delivery.',
      tags: %w[review quality],
      rules_md: <<~MD
        # Code Review Rules

        - Prefer small, focused commits with clear messages.
        - Add or update tests alongside behavior changes.
        - Avoid risky patterns; call out security concerns explicitly.
        - Ensure migrations are reversible and safe for large datasets.
        - Verify logging and observability for critical paths.

        ## Code Review Rules - Detailed
        Use concise language and point to specific files/lines when possible.
      MD
    },
    {
      name: 'Code Review Best Practices',
      version: 1,
      summary: 'Provide concise, high-level findings with a focus on risk, tests, and next steps.',
      tags: %w[review clarity testing],
      rules_md: <<~MD
        ## Code Review Best Practices

        1. Focus on **high-risk areas** (security, data integrity, complex logic) before nitpicks.
        2. Highlight **missing tests**, especially regression, integration, or platform coverage gaps.
        3. Call out **blocking issues** and describe why they matter instead of just marking them.
        4. Suggest **next steps** so the author understands the intended fix or follow-up.
        5. Keep comments **concise and actionable** to respect author bandwidth.
      MD
    },
    {
      name: 'Backend Engineering Guidelines',
      version: 1,
      summary: 'Standardize backend changes with logging, observability, and safety checks.',
      tags: %w[backend logging safety],
      rules_md: <<~MD
        ## Backend Engineering Guidelines

        - Validate **input and downstream responses** to prevent silent failures.
        - Add or update **metrics/logs** when introducing new behavior or toggles.
        - Ensure **feature flags** and config guards are present for risky toggles.
        - Include **explainers or runbooks** for non-obvious behavior changes.
        - Confirm **database migrations** follow zero-downtime patterns and include rollbacks.
      MD
    },
    {
      name: 'Default',
      version: 1,
      summary: 'Default ruleset for agents.',
      tags: %w[default],
      rules_md: <<~MD
        - Keep responses concise
        - No secrets or PII
        - Cite file paths where relevant
      MD
    },
    {
      name: 'SafeOps',
      version: 1,
      summary: 'Safe operations ruleset.',
      tags: %w[safety],
      rules_md: <<~MD
        - Never execute destructive commands without confirmation
        - Prefer read-only tools where possible
      MD
    }
  ]

  ruleset_ids = {}
  rulesets_data.each do |r|
    rid = db.create_ruleset(
      r[:name],
      nil,
      version: r[:version],
      summary: r[:summary],
      rules_md: r[:rules_md],
      tags: r[:tags],
      notes: r[:notes]
    )
    ruleset_ids[r[:name]] = rid
  end

  # =========================
  # Think Workflows
  # NOTE: Workflows no longer have driver_version or rules fields.
  # Drivers are now managed by the Drivers engine separately.
  # =========================
  workflow_ids = []

  workflows_yaml = {
    'example_workflow' => <<~YAML,
      ---
      id: example_workflow
      name: Example WF
      description: One-line description so think_workflows_list can display helpful text.
      version: 4
      steps:
      - id: '1'
        call: prompt_say
        input_template:
          text: 'Example workflow running for {{params.ticket_key}}\n\n      '
      - id: '2'
        deps:
        - '1'
        call: prompt_say
        input_template:
          text: "âœ… Finished {{workflow}} for {{params.ticket_key}}\n"
    YAML
    'develop_ticket_v1' => <<~YAML,
      ---
      id: develop_ticket_v1
      name: develop_ticket_v1
      description: WF for development of a ticket
      version: 3
      steps:
      - id: '1'
        call: jira_get_issue
        input_template:
          key: "{{params.issueKey}}"
        capture_as: ticket
      - id: '2'
        call: ci.checkout
        deps:
        - '1'
        input_template:
          ref: "{{params.base_branch}}"
      - id: '3'
        call: ci.create_branch
        deps:
        - '2'
        input_template:
          name: "{{params.feature_branch}}"
      - id: '4'
        call: fts_search
        deps:
        - '3'
        input_template:
          q: "{{params.issueKey}}"
        capture_as: code_refs
      - id: '5'
        call: ci.run_tests
        deps:
        - '4'
        input_template:
          ref: "{{params.feature_branch}}"
      - id: '6'
        call: ci.open_pr
        deps:
        - '5'
        input_template:
          title: "[{{params.issueKey}}] {{params.title}}"
          base: "{{params.base_branch}}"
          head: "{{params.feature_branch}}"
    YAML
    'ticket_grooming_v1' => <<~YAML,
      ---
      id: ticket_grooming_v1
      name: Ticket Grooming
      description: 'Ticket grooming workflow '
      version: 3
      steps:
      - id: 1
        name: fetch_ticket
        call: jira_get_issue
        input_template:
          key: "{{params.issueKey}}"
        capture_as: ticket
      - id: 2
        name: scan_repo_context
        call: fts_search
        deps:
        - 1
        input_template:
          q: "{{params.issueKey}} OR {{ticket.fields.summary}}"
        capture_as: similar_code
      - id: 3
        name: enumerate_resources
        call: memory_resources_list
        deps:
        - 1
        input_template:
          repo:
        capture_as: resources
      - id: 4
        name: planning_guides
        call: fts_search
        deps:
        - 3
        input_template:
          q: ACCEPTANCE CRITERIA|CONTRIBUTING|DESIGN|ADR|PLAYBOOK|README
        capture_as: guidelines
      - id: 5
        name: list_diffs
        call: prompt_say
        deps:
        - 2
        input_template:
          text: look at all the changes in repo and list them file by file.
    YAML
    'code_review_initial' => <<~YAML,
      ---
      id: code_review_initial
      name: Code Review Initial
      description: 'Phase 1 of code review: Data collection, quality gates, and initial
        analysis. Uses GitLab MCP for diffs (non-blocking). Writes intermediate state file
        for code_review_final to consume.'
      version: 1
      steps:
      - id: announce_start
        call: prompt_say
        input_template:
          text: |
            Code Review Initial (Phase 1/2)

            Collecting data -> Running quality gates -> Analyzing code
            Will write intermediate state to: .savant/code-review/{ticket}-state.json
      - id: load_config
        call: local.read
        deps:
        - announce_start
        input_template:
          files:
          - ".cline/config.yml"
        capture_as: config_raw
      - id: parse_config
        call: analysis.parse_yaml
        deps:
        - load_config
        input_template:
          yaml: "{{config_raw}}"
          extract:
          - project_gitlab
          - project_code
        capture_as: project
      - id: normalize_mr_param
        call: analysis.normalize_text
        deps:
        - parse_config
        input_template:
          text: "{{params.mr_iid}}"
          strip: "!"
          type: integer
        capture_as: mr_iid
      - id: fetch_mr
        call: gitlab.get_merge_request
        deps:
        - normalize_mr_param
        input_template:
          project: "{{project.project_gitlab}}"
          mr_iid: "{{mr_iid}}"
        capture_as: mr_data
      - id: fetch_mr_changes
        call: gitlab.get_merge_request_changes
        deps:
        - fetch_mr
        input_template:
          project: "{{project.project_gitlab}}"
          mr_iid: "{{mr_iid}}"
        capture_as: mr_changes_data
      - id: checkout_branch
        call: local.exec
        deps:
        - fetch_mr
        input_template:
          cmd: |
            git fetch origin {{mr_data.source_branch}} 2>&1 && \
            git checkout {{mr_data.source_branch}} 2>&1 || echo "SKIPPED: git checkout failed or not a git repo"
        capture_as: checkout_raw
      - id: safe_dev_migrate_on_checkout
        call: local.exec
        deps:
        - checkout_branch
        input_template:
          cmd: |
            if ls config/database.yml db/schema.rb Gemfile >/dev/null 2>&1; then \
              (bundle exec rake db:migrate RAILS_ENV=development 2>&1 || echo "SKIPPED_DEV_MIGRATE"); \
            else \
              echo "SKIPPED: no Rails DB files"; \
            fi
          note: Run a safe development migration after checkout; harmless no-op if no migrations
            pending.
        capture_as: safe_dev_migrate_raw
      - id: extract_changed_files_from_gitlab
        call: analysis.extract_changed_paths
        deps:
        - fetch_mr_changes
        input_template:
          changes: "{{mr_changes_data}}"
          note: Extract file list from GitLab MR changes API (non-blocking)
        capture_as: changed_files_list
      - id: extract_diffs_from_gitlab
        call: analysis.extract_diffs
        deps:
        - fetch_mr_changes
        input_template:
          changes: "{{mr_changes_data}}"
          note: Extract full diffs from GitLab MR changes API (non-blocking)
        capture_as: full_diff_text
      - id: diff_summary
        call: analysis.diff_summary
        deps:
        - extract_diffs_from_gitlab
        - extract_changed_files_from_gitlab
        input_template:
          diff: "{{full_diff_text}}"
          note: Summarize changed files, languages, LOC, and intent (compact).
        capture_as: change_summary
      - id: get_metadata
        call: local.exec
        deps:
        - fetch_mr
        input_template:
          cmd: |
            echo "sha=$(git rev-parse --short HEAD 2>/dev/null || echo 'unknown')"
            echo "date=$(date +%Y-%m-%d)"
            echo "timestamp=$(date +%Y%m%d-%H%M%S)"
        capture_as: metadata_raw
      - id: analyze_metadata
        call: analysis.parse_first_line
        deps:
        - get_metadata
        input_template:
          text: "{{metadata_raw}}"
        capture_as: metadata
      - id: describe_diff_summary
        call: analysis.diff_summary
        deps:
        - diff_summary
        input_template:
          diff: "{{change_summary}}"
          note: Create a short diff description for the review brief.
        capture_as: brief
      - id: quality_gates
        call: analysis.evaluate_quality
        deps:
        - diff_summary
        input_template:
          data: "{{change_summary}}"
        capture_as: quality_results
    YAML
    'code_review_final' => <<~YAML
      ---
      id: code_review_final
      name: Code Review Final
      description: 'Phase 2 of code review: Impact analysis, cross-repo search, visual diagrams,
        and final safety decision. Reads intermediate state from code_review_initial. All
        operations are non-blocking (no local git/shell commands).'
      version: 4
      steps:
      - id: '1'
        call: prompt_say
        input_template:
          text: |
            Code Review Final (Phase 2/2)

            Loading state -> Impact analysis -> Visual diagrams -> Final verdict
            Reading from: .savant/code-review/{{params.ticket}}-*-state.json
      - id: '2'
        call: local.exec
        deps:
        - '1'
        input_template:
          cmd: 'ls -t .savant/code-review/{{params.ticket}}-*-state.json 2>/dev/null | head
            -1 || echo "NOT_FOUND"

            '
          note: Find most recent state file for ticket
        capture_as: state_file_path_raw
      - id: '3'
        call: analysis.parse_first_line
        deps:
        - '2'
        input_template:
          text: "{{state_file_path_raw}}"
          note: Extract file path from command output
        capture_as: state_file_path
      - id: '4'
        call: local.read
        deps:
        - '3'
        input_template:
          files:
          - "{{state_file_path}}"
        capture_as: state_json_raw
      - id: '5'
        call: analysis.parse_json
        deps:
        - '4'
        input_template:
          json: "{{state_json_raw}}"
          note: Parse intermediate state JSON
        capture_as: state
      - id: '6'
        call: analysis.validate_code_review_state
        deps:
        - '5'
        input_template:
          state: "{{state}}"
          note: |
            LLM validates state has required fields:
            {
              "valid": bool,
              "missing_fields": [...],
              "error": "..." or null
            }
        capture_as: state_validation
      - id: '7'
        call: prompt_say
        deps:
        - '6'
        input_template:
          text: |
            State Loaded: {{state.ticket}}

            MR: !{{state.mr_iid}}
            Date: {{state.date}}
            Commit: {{state.commit_sha}}
            Quality: {{state.quality_summary.overall_status}}
    YAML
  }

  workflows_yaml.each do |workflow_id, yaml_text|
    data = YAML.safe_load(yaml_text) || {}
    db.create_think_workflow(
      workflow_id: workflow_id,
      name: data['name'] || workflow_id,
      description: data['description'] || '',
      version: (data['version'] || 1).to_i,
      steps: data['steps'] || []
    )
    workflow_ids << workflow_id
  end

  # =========================
  # Sample Agent
  # =========================
  begin
    db.create_agent(
      name: 'Sample Agent',
      persona_id: persona_ids['savant-engineer'],
      driver_prompt: nil,
      driver_name: 'search',
      rule_set_ids: [ruleset_ids['Default']].compact,
      favorite: true
    )
  rescue StandardError
    # ignore
  end

  result = {
    ok: true,
    db: db_name,
    personas: persona_ids.keys,
    drivers: driver_names,
    rulesets: ruleset_ids.keys,
    workflows: workflow_ids,
    agents: ['Sample Agent']
  }

  # Pretty-print JSON for better readability in CLI output
  puts JSON.pretty_generate(result)
  exit 0
rescue StandardError => e
  error_payload = { ok: false, error: e.message, class: e.class.name }
  warn JSON.pretty_generate(error_payload)
  exit 1
end
