#!/usr/bin/env ruby
# frozen_string_literal: true

require 'json'
require_relative '../lib/savant/framework/db'

def env_flag(name, default = nil)
  v = ENV[name]
  (v && !v.to_s.empty?) ? v : default
end

db_env = (env_flag('DB_ENV', env_flag('RAILS_ENV', env_flag('RACK_ENV', 'development')))).to_s
db_name = env_flag('DB_NAME', db_env == 'test' ? 'savant_test' : 'savant_development')

begin
  # Hint PG which DB to use when not providing DATABASE_URL
  ENV['PGDATABASE'] ||= db_name

  db = Savant::Framework::DB.new

  # Personas (idempotent)
  personas = [
    ['savant-engineer', nil],
    ['architect', nil],
    ['reviewer', nil]
  ]
  persona_ids = {}
  personas.each do |name, content|
    pid = db.create_persona(name, content)
    persona_ids[name] = pid
  end

  # Rulesets (idempotent)
  rules = [
    ['Default', "- Keep responses concise\n- No secrets or PII\n- Cite file paths where relevant"],
    ['SafeOps', "- Never execute destructive commands without confirmation\n- Prefer read-only tools where possible"]
  ]
  rule_ids = {}
  rules.each do |name, content|
    rid = db.create_ruleset(name, content)
    rule_ids[name] = rid
  end

  # Sample Agent (idempotent via upsert on name)
  begin
    db.create_agent(
      name: 'Sample Agent',
      persona_id: persona_ids['savant-engineer'],
      driver_prompt: nil,
      driver_name: 'search',
      rule_set_ids: [rule_ids['Default']].compact,
      favorite: true
    )
  rescue StandardError
    # ignore
  end

  # Seed a Drivers catalog prompt for code review (idempotent via create/update)
  begin
    require_relative '../lib/savant/engines/drivers/ops'
    ops = Savant::Drivers::Ops.new
    code_review_md = <<~MD
      # Savant - Code Review
      ---
      ## Orchestration Loop

      Always follow this loop:

      1. Call `think_plan` first
      2. Execute exactly the tool in `instruction.call` with its `input_template`
      3. Pass the tool result to `think_next`
      4. Repeat until `done == true`
      5. If any required tool is missing or invalid, abort and notify

      **Discovery**: To find available workflows, call `think_workflows_list`, then pick one and call `think_plan` with its id and params.

      ---

      ## Execution Rules

      ### Determinism
      - Given the same workflow, params, and validated outputs, the sequence is **fixed**
      - **Be strict**: Do not invent tools or schema fields. Use only what the registrar advertises
      - Follow the DAG dependencies exactly
      - Keep rationale concise and actionable

      ### Payload Discipline

      Keep `think_next` payloads compact (< 50KB). Do not paste large file contents, diffs, or entire tickets.

      **Prefer**: summaries, counts, and file:line references. If an artifact is large, save it locally and return a path + hash + short preview.

      **Good**:
      ```json
      {
        "status": "failed",
        "offenses": { "count": 15, "by_severity": { "error": 2, "warning": 8 } },
        "summary": "15 offenses in 3 files"
      }
      ```

      **Bad**:
      ```json
      {
        "raw_output": "...500 lines of RuboCop output...",
        "full_diff": "...10000 lines of git diff..."
      }
      ```

      ### Analysis Tool Responses

      Every `analysis.*` tool MUST return this structure:

      ```json
      {
        "status": "passed|failed|skipped|error",
        "summary": "Human-readable 1-2 sentence summary",
        "details": {
          // Tool-specific metrics (keep minimal)
        },
        "recommendations": [
          // Actionable items only (max 5)
        ]
      }
      ```

      ### Local Actions

      For instructions where `call` looks like `local.exec`, `local.read`, `local.write`, or `local.search`:
      - `local.search`: Use your editor/terminal to search files with given `q` and `globs`
      - `local.exec`: Run the provided shell `cmd` in the project root and capture output
      - `local.read`: Read files and return content
      - `local.write`: Write files
      - Return snapshots of findings/output to `think_next`

      **Local exec usage**:
      - OK: Running quality gates (RuboCop, RSpec, ESLint)
      - OK: Running security scans (Brakeman, bundler-audit)
      - OK: Database migrations
      - Avoid: Getting diffs (use `gitlab.get_merge_request_changes` instead)
      - Avoid: Listing changed files (use GitLab MCP)

      ### Cross-Service Calls

      For instructions where `call` is a tool exposed by another MCP service:
      - `gitlab.*` -> GitLab MCP (e.g., `gitlab.get_merge_request_changes`)
      - `fts_search` -> Context MCP full-text search
      - `memory_search` -> Context MCP memory search
      - `jira_get_issue` -> Jira MCP

      Call that service directly and pass the result to `think_next`.

      ---

      ## Code Review Standards

      ### Backend (Ruby/Rails)
      - RuboCop: 0 offenses (or documented exceptions)
      - RSpec: >=85% coverage, all passing
      - Brakeman: No high-confidence warnings
      - No SQL injection, proper authorization checks
      - Migrations: Reversible, non-destructive, indexed

      ### Frontend (React/TypeScript)
      - ESLint: 0 errors
      - TypeScript: No `any` types
      - Test coverage: >=90%
      - No XSS vulnerabilities

      ### Security
      - No hardcoded secrets (API keys, tokens, credentials)
      - No debug statements (binding.pry, console.log, debugger)
      - Input validation, parameterized queries
      - Proper authentication & authorization

      ### Database
      - Migrations reversible with `down` methods
      - No destructive operations without backup plan
      - Proper indexes for foreign keys

      ---

      ## Analysis Tools

      All `analysis.*` tools return structured JSON. Key tools:

      - `analysis.classify_mr_changes` - Classify change types (backend, frontend, migrations, database)
      - `analysis.parse_rspec` - Parse RSpec output, detect migration errors, trigger auto-retry
      - `analysis.parse_rubocop` - Parse RuboCop output
      - `analysis.parse_eslint` - Parse ESLint output
      - `analysis.parse_security_scans` - Parse Brakeman, bundler-audit, npm audit
      - `analysis.detect_secrets_in_diff` - Detect hardcoded secrets in diffs
      - `analysis.evaluate_safety` - Final safety verdict (SAFE/CAUTION/RISKY)
      - `analysis.extract_diffs` - Extract diff text from GitLab MR changes API
      - `analysis.extract_changed_paths` - Extract file list from GitLab API

      ---

      ## Commit Analysis

      Red flags: Functional regressions, bypassed validation, incomplete testing, multiple fix commits for same feature

      Green flags: Better data integrity, corrects test anti-patterns, catches production issues early

      ---

      ## Workflows

      ### code_review_initial (Phase 1)
      1. GitLab MCP: Fetch MR data, diffs, files (non-blocking)
      2. Classify changes, run quality gates (RuboCop, RSpec, ESLint)
      3. Run security scans (Brakeman, audits)
      4. Ensure local branch context: checkout MR source branch, then run a safe dev DB migrate (no-op if not Rails).
      4. Generate initial report: `code-reviews/{TICKET}/{DATE}/code_review_initial.md` (embed Change Graph)
      5. Write state: `.savant/code-review/{TICKET}-{TIMESTAMP}-state.json`
      6. Decision: If initial gates pass, proceed to `code_review_final` with `ticket={TICKET}`

      Pattern scans policy (Phase 1)
      - Search only within the changed files from the MR (use local search/terminal).
      - Do not use Context FTS for pattern scans in Phase 1.

      ### code_review_final (Phase 2)
      1. Load state from Phase 1
      2. Impact analysis, cross-repo search (FTS + memory MCP)
      3. Requirements gap analysis, generate Mermaid diagrams (impact graph + sequence)
      4. Final safety decision
      5. Write final report: `code-reviews/{TICKET}/{DATE}/code_review_final.md` (embed both diagrams)

      Database policy
      - Phase 1 (Initial): Run DB migration status/migrate commands only when MR changes include migration files.
      - Phase 2 (Final): No DB operations are executed; analysis only.

      ---

      ## Error Handling

      - **Missing tools**: Abort and notify (do not invent or substitute)
      - **Large payloads**: Summarize before passing to `think_next` (save artifacts to files)
      - **RSpec migration failures**: Auto-detect, run migrations, retry RSpec
      - **Workflow failures**: Re-run failed phase (state preserved for Phase 2)

      ---

      ## Quality Thresholds

      **Must Pass**: RuboCop 0 offenses, RSpec >=85% coverage, ESLint 0 errors, No critical/high security vulnerabilities

      **Warnings**: Test coverage 70-85%, moderate vulnerabilities, partial requirements

      **Blockers**: Test coverage < 70%, critical vulnerabilities, hardcoded secrets, destructive migrations without backup, functional regressions
    MD
    summary = 'Code review orchestrator prompt for Think/Drivers workflows'
    begin
      ops.get(name: 'code_review')
      ops.update(name: 'code_review', summary: summary, prompt_md: code_review_md, tags: %w[review workflow])
    rescue StandardError
      ops.create(name: 'code_review', summary: summary, prompt_md: code_review_md, tags: %w[review workflow])
    end

    # Seed/Update the 'search' driver prompt
    search_md = <<~MD
      Objective: Given the Goal (run input), search local indexed repos and memory bank, then produce a concise, accurate summary.

      Required steps:

      action=tool, tool_name=context.fts_search, args={"q": Goal, "repo": null, "limit": 10}
      action=tool, tool_name=context.memory_search, args={"q": Goal, "repo": null, "limit": 10}
      action=reason (optional): synthesize findings if needed
      action=finish: deliver a concise summary
      Constraints:

      Do not output action="finish" before at least one tool call.
      Use fully qualified tool names exactly as listed.
      ONE JSON object per step with keys: action, tool_name, args, final, reasoning.
      Map Goal verbatim to args.q. Keep reasoning short.
    MD
    search_summary = 'Default search driver (Context FTS + Memory)'
    begin
      ops.get(name: 'search')
      ops.update(name: 'search', summary: search_summary, prompt_md: search_md, tags: %w[search summary])
    rescue StandardError
      ops.create(name: 'search', summary: search_summary, prompt_md: search_md, tags: %w[search summary])
    end
  rescue StandardError
    # ignore driver seeding errors
  end

  puts({ ok: true, db: db_name, personas: persona_ids.keys, rulesets: rule_ids.keys, agents: ['Sample Agent'] }.to_json)
  exit 0
rescue StandardError => e
  warn({ ok: false, error: e.message, class: e.class.name }.to_json)
  exit 1
end
